"""Sistema de carregamento de dados CSV com m√∫ltiplas fontes e valida√ß√µes robustas.

‚ö†Ô∏è CONFORMIDADE CR√çTICA: Este m√≥dulo deve ser usado APENAS pelo agente de ingest√£o.
Agentes de resposta devem consultar exclusivamente a tabela embeddings do Supabase.

Este m√≥dulo implementa o carregamento inteligente de dados CSV com suporte a:
- Arquivos locais com detec√ß√£o autom√°tica de encoding (RESTRITO)
- URLs remotas (HTTP/HTTPS) (RESTRITO)
- DataFrames pandas existentes (PERMITIDO)
- Dados sint√©ticos para testes (PERMITIDO)
- Upload via base64 (RESTRITO)
- Valida√ß√£o robusta de formato e conte√∫do
"""
from __future__ import annotations
import io
import os
import base64
import requests
import chardet
import pandas as pd
import numpy as np
import inspect
from typing import Any, Dict, List, Optional, Union, Tuple
from pathlib import Path
from urllib.parse import urlparse
import warnings
from datetime import datetime, timedelta

from src.utils.logging_config import get_logger


class DataLoaderError(Exception):
    """Exce√ß√£o personalizada para erros de carregamento de dados."""
    pass


class UnauthorizedCSVAccessError(Exception):
    """Exce√ß√£o lan√ßada quando acesso n√£o autorizado a CSV √© detectado."""
    pass


class DataLoader:
    """Carregador inteligente de dados CSV com m√∫ltiplas fontes e valida√ß√µes.
    
    ‚ö†Ô∏è CONFORMIDADE: Restrito ao agente de ingest√£o apenas.
    """
    
    def __init__(self, caller_agent: Optional[str] = None):
        self.logger = get_logger(__name__)
        self._last_loaded_info: Optional[Dict[str, Any]] = None
        
        # Detectar e validar caller_agent
        self.caller_agent = caller_agent or self._detect_caller_agent()
        
        # Configura√ß√µes padr√£o
        self.default_encoding = 'utf-8'
        self.supported_encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252', 'utf-16']
        self.max_file_size_mb = 500
        self.timeout_seconds = 30
        
        self.logger.info(f"DataLoader inicializado por: {self.caller_agent}")
    
    def _detect_caller_agent(self) -> str:
        """Detecta qual agente est√° chamando este carregador."""
        frame = inspect.currentframe()
        try:
            # Subir na stack para encontrar o caller
            for i in range(15):  # Limite de seguran√ßa aumentado
                frame = frame.f_back
                if frame is None:
                    break
                    
                filename = frame.f_code.co_filename
                
                # Verificar se √© um agente conhecido
                if 'ingestion_agent' in filename or 'data_ingestion' in filename:
                    return 'ingestion_agent'
                elif 'data_processor' in filename:
                    return 'data_processor'  # DataProcessor pode ser chamado por v√°rios agentes
                elif 'orchestrator_agent' in filename:
                    return 'orchestrator_agent'
                elif 'csv_analysis_agent' in filename or 'embeddings_analysis_agent' in filename:
                    return 'analysis_agent'
                elif 'rag_agent' in filename:
                    return 'rag_agent'
                elif 'test_' in filename or '_test' in filename:
                    return 'test_system'
                    
            return 'unknown_caller'
            
        finally:
            del frame
    
    def _validate_csv_access_authorization(self) -> None:
        """Valida se o caller tem autoriza√ß√£o para acessar CSV diretamente."""
        authorized_agents = [
            'ingestion_agent',
            'data_processor',       # DataProcessor pode ser usado por ingest√£o
            'data_loading_system',  # Para casos de carregamento inicial
            'test_system'           # Para testes
        ]
        
        if self.caller_agent not in authorized_agents:
            error_msg = (
                f"‚ö†Ô∏è VIOLA√á√ÉO DE CONFORMIDADE DETECTADA!\n"
                f"Agente '{self.caller_agent}' tentou acessar CSV diretamente via DataLoader.\n"
                f"Apenas agentes autorizados podem ler CSV: {authorized_agents}\n"
                f"Agentes de resposta devem usar APENAS a tabela embeddings."
            )
            self.logger.error(error_msg)
            raise UnauthorizedCSVAccessError(error_msg)
        
        self.logger.info(f"‚úÖ DataLoader: Acesso autorizado para agente: {self.caller_agent}")
    
    def load_from_file(self, file_path: str, **pandas_kwargs) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """Carrega dados de arquivo local com detec√ß√£o autom√°tica de encoding.
        
        ‚ö†Ô∏è CONFORMIDADE: Apenas agente de ingest√£o autorizado.
        
        Args:
            file_path: Caminho para o arquivo CSV
            **pandas_kwargs: Argumentos adicionais para pd.read_csv()
            
        Returns:
            Tuple com (DataFrame, informa√ß√µes do carregamento)
            
        Raises:
            DataLoaderError: Se houver erro no carregamento
            UnauthorizedCSVAccessError: Se chamador n√£o autorizado
        """
        self._validate_csv_access_authorization()
        
        try:
            file_path = Path(file_path).resolve()
            
            if not file_path.exists():
                raise DataLoaderError(f"Arquivo n√£o encontrado: {file_path}")
            
            if not file_path.is_file():
                raise DataLoaderError(f"Caminho n√£o √© um arquivo: {file_path}")
            
            # Verificar tamanho do arquivo
            file_size_mb = file_path.stat().st_size / (1024 * 1024)
            if file_size_mb > self.max_file_size_mb:
                raise DataLoaderError(f"Arquivo muito grande: {file_size_mb:.1f}MB (m√°ximo: {self.max_file_size_mb}MB)")
            
            self.logger.warning(f"üö® ACESSO CSV AUTORIZADO por {self.caller_agent}: {file_path} ({file_size_mb:.1f}MB)")
            
            # Detectar encoding se n√£o especificado
            encoding = pandas_kwargs.get('encoding')
            if not encoding:
                encoding = self._detect_encoding(file_path)
                pandas_kwargs['encoding'] = encoding
            
            # Configura√ß√µes padr√£o
            default_kwargs = {
                'low_memory': False,
                'encoding': encoding
            }
            default_kwargs.update(pandas_kwargs)
            
            # Carregar dados
            df = pd.read_csv(file_path, **default_kwargs)
            
            # Informa√ß√µes do carregamento
            load_info = {
                'source_type': 'file',
                'source_path': str(file_path),
                'file_size_mb': file_size_mb,
                'encoding': encoding,
                'rows': len(df),
                'columns': len(df.columns),
                'memory_usage_mb': df.memory_usage(deep=True).sum() / (1024 * 1024),
                'load_time': datetime.now().isoformat(),
                'pandas_kwargs': default_kwargs
            }
            
            self._last_loaded_info = load_info
            self.logger.info(f"‚úÖ Arquivo carregado: {load_info['rows']} linhas, {load_info['columns']} colunas")
            
            return df, load_info
            
        except Exception as e:
            error_msg = f"Erro ao carregar arquivo {file_path}: {str(e)}"
            self.logger.error(error_msg)
            raise DataLoaderError(error_msg) from e
    
    def load_from_url(self, url: str, **pandas_kwargs) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """Carrega dados de URL remota.
        
        ‚ö†Ô∏è CONFORMIDADE: Apenas agente de ingest√£o autorizado.
        
        Args:
            url: URL do arquivo CSV
            **pandas_kwargs: Argumentos adicionais para pd.read_csv()
            
        Returns:
            Tuple com (DataFrame, informa√ß√µes do carregamento)
            
        Raises:
            DataLoaderError: Se houver erro no carregamento
            UnauthorizedCSVAccessError: Se chamador n√£o autorizado
        """
        self._validate_csv_access_authorization()
        
        try:
            # Validar URL
            parsed_url = urlparse(url)
            if not parsed_url.scheme in ['http', 'https']:
                raise DataLoaderError(f"URL deve usar HTTP ou HTTPS: {url}")
            
            self.logger.warning(f"üö® ACESSO CSV VIA URL AUTORIZADO por {self.caller_agent}: {url}")
            
            # Fazer request com timeout
            response = requests.get(url, timeout=self.timeout_seconds, stream=True)
            response.raise_for_status()
            
            # Verificar tamanho
            content_length = response.headers.get('content-length')
            if content_length:
                size_mb = int(content_length) / (1024 * 1024)
                if size_mb > self.max_file_size_mb:
                    raise DataLoaderError(f"Arquivo muito grande: {size_mb:.1f}MB (m√°ximo: {self.max_file_size_mb}MB)")
            
            # Detectar encoding do conte√∫do
            content = response.content
            encoding = pandas_kwargs.get('encoding')
            if not encoding:
                detected = chardet.detect(content)
                encoding = detected.get('encoding', 'utf-8')
                pandas_kwargs['encoding'] = encoding
            
            # Configura√ß√µes padr√£o
            default_kwargs = {
                'low_memory': False,
                'encoding': encoding
            }
            default_kwargs.update(pandas_kwargs)
            
            # Carregar dados
            df = pd.read_csv(io.BytesIO(content), **default_kwargs)
            
            # Informa√ß√µes do carregamento
            load_info = {
                'source_type': 'url',
                'source_path': url,
                'file_size_mb': len(content) / (1024 * 1024),
                'encoding': encoding,
                'rows': len(df),
                'columns': len(df.columns),
                'memory_usage_mb': df.memory_usage(deep=True).sum() / (1024 * 1024),
                'load_time': datetime.now().isoformat(),
                'pandas_kwargs': default_kwargs,
                'response_headers': dict(response.headers)
            }
            
            self._last_loaded_info = load_info
            self.logger.info(f"‚úÖ URL carregada: {load_info['rows']} linhas, {load_info['columns']} colunas")
            
            return df, load_info
            
        except UnauthorizedCSVAccessError:
            raise  # Re-lan√ßar erro de autoriza√ß√£o
        except Exception as e:
            error_msg = f"Erro ao carregar URL {url}: {str(e)}"
            self.logger.error(error_msg)
            raise DataLoaderError(error_msg) from e
    
    def load_from_dataframe(self, df: pd.DataFrame, source_info: str = "dataframe") -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """Carrega dados de um DataFrame pandas existente.
        
        Args:
            df: DataFrame pandas
            source_info: Informa√ß√£o sobre a origem dos dados
            
        Returns:
            Tuple com (DataFrame, informa√ß√µes do carregamento)
        """
        if not isinstance(df, pd.DataFrame):
            raise DataLoaderError("Entrada deve ser um pandas DataFrame")
        
        if df.empty:
            raise DataLoaderError("DataFrame est√° vazio")
        
        # Fazer c√≥pia para evitar modifica√ß√µes n√£o intencionais
        df_copy = df.copy()
        
        # Informa√ß√µes do carregamento
        load_info = {
            'source_type': 'dataframe',
            'source_path': source_info,
            'rows': len(df_copy),
            'columns': len(df_copy.columns),
            'memory_usage_mb': df_copy.memory_usage(deep=True).sum() / (1024 * 1024),
            'load_time': datetime.now().isoformat(),
            'original_dtypes': df_copy.dtypes.to_dict()
        }
        
        self._last_loaded_info = load_info
        self.logger.info(f"‚úÖ DataFrame carregado: {load_info['rows']} linhas, {load_info['columns']} colunas")
        
        return df_copy, load_info
    
    def load_from_base64(self, base64_content: str, filename: str = "upload.csv", **pandas_kwargs) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """Carrega dados de string base64 (√∫til para upload de arquivos).
        
        ‚ö†Ô∏è CONFORMIDADE: Apenas agente de ingest√£o autorizado.
        
        Args:
            base64_content: Conte√∫do CSV codificado em base64
            filename: Nome do arquivo para refer√™ncia
            **pandas_kwargs: Argumentos adicionais para pd.read_csv()
            
        Returns:
            Tuple com (DataFrame, informa√ß√µes do carregamento)
            
        Raises:
            DataLoaderError: Se houver erro no carregamento
            UnauthorizedCSVAccessError: Se chamador n√£o autorizado
        """
        self._validate_csv_access_authorization()
        
        try:
            self.logger.warning(f"üö® ACESSO CSV VIA UPLOAD AUTORIZADO por {self.caller_agent}: {filename}")
            
            # Decodificar base64
            content = base64.b64decode(base64_content)
            
            # Verificar tamanho
            size_mb = len(content) / (1024 * 1024)
            if size_mb > self.max_file_size_mb:
                raise DataLoaderError(f"Arquivo muito grande: {size_mb:.1f}MB (m√°ximo: {self.max_file_size_mb}MB)")
            
            self.logger.info(f"Processando upload: {filename} ({size_mb:.1f}MB)")
            
            # Detectar encoding
            encoding = pandas_kwargs.get('encoding')
            if not encoding:
                detected = chardet.detect(content)
                encoding = detected.get('encoding', 'utf-8')
                pandas_kwargs['encoding'] = encoding
            
            # Configura√ß√µes padr√£o
            default_kwargs = {
                'low_memory': False,
                'encoding': encoding
            }
            default_kwargs.update(pandas_kwargs)
            
            # Carregar dados
            df = pd.read_csv(io.BytesIO(content), **default_kwargs)
            
            # Informa√ß√µes do carregamento
            load_info = {
                'source_type': 'base64_upload',
                'source_path': filename,
                'file_size_mb': size_mb,
                'encoding': encoding,
                'rows': len(df),
                'columns': len(df.columns),
                'memory_usage_mb': df.memory_usage(deep=True).sum() / (1024 * 1024),
                'load_time': datetime.now().isoformat(),
                'pandas_kwargs': default_kwargs
            }
            
            self._last_loaded_info = load_info
            self.logger.info(f"‚úÖ Upload processado: {load_info['rows']} linhas, {load_info['columns']} colunas")
            
            return df, load_info
            
        except UnauthorizedCSVAccessError:
            raise  # Re-lan√ßar erro de autoriza√ß√£o
        except Exception as e:
            error_msg = f"Erro ao processar upload {filename}: {str(e)}"
            self.logger.error(error_msg)
            raise DataLoaderError(error_msg) from e
    
    def create_synthetic_data(self, data_type: str = "generic", num_rows: int = 1000, **kwargs) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """Cria dados sint√©ticos para testes e demonstra√ß√µes.
        
        Args:
            data_type: Tipo de dados sint√©ticos ('sales', 'customer', 'generic')
            num_rows: N√∫mero de linhas a gerar
            **kwargs: Argumentos espec√≠ficos para cada tipo de dados
            
        Returns:
            Tuple com (DataFrame, informa√ß√µes do carregamento)
        """
        if num_rows <= 0:
            raise DataLoaderError("N√∫mero de linhas deve ser positivo")
        
        if num_rows > 100000:
            raise DataLoaderError("N√∫mero m√°ximo de linhas para dados sint√©ticos: 100,000")
        
        self.logger.info(f"Gerando dados sint√©ticos: {data_type} ({num_rows} linhas)")
        
        # Seed para reprodutibilidade
        seed = kwargs.get('seed', 42)
        np.random.seed(seed)
        
        if data_type == "sales":
            df = self._create_sales_data(num_rows, **kwargs)
        elif data_type == "customer":
            df = self._create_customer_data(num_rows, **kwargs)
        elif data_type == "generic":
            df = self._create_generic_data(num_rows, **kwargs)
        else:
            raise DataLoaderError(f"Tipo de dados sint√©ticos n√£o suportado: {data_type}. Op√ß√µes: 'sales', 'customer', 'generic'")
        
        # Informa√ß√µes do carregamento
        load_info = {
            'source_type': 'synthetic',
            'source_path': f"synthetic_{data_type}",
            'data_type': data_type,
            'rows': len(df),
            'columns': len(df.columns),
            'memory_usage_mb': df.memory_usage(deep=True).sum() / (1024 * 1024),
            'load_time': datetime.now().isoformat(),
            'generation_params': {'num_rows': num_rows, 'seed': seed, **kwargs}
        }
        
        self._last_loaded_info = load_info
        self.logger.info(f"‚úÖ Dados sint√©ticos gerados: {load_info['rows']} linhas, {load_info['columns']} colunas")
        
        return df, load_info
    
    def get_last_load_info(self) -> Optional[Dict[str, Any]]:
        """Retorna informa√ß√µes do √∫ltimo carregamento realizado."""
        return self._last_loaded_info
    
    def _detect_encoding(self, file_path: Path) -> str:
        """Detecta encoding de arquivo automaticamente."""
        try:
            # Ler amostra do arquivo
            with open(file_path, 'rb') as f:
                sample = f.read(10240)  # 10KB
            
            # Detectar encoding
            result = chardet.detect(sample)
            confidence = result.get('confidence', 0)
            detected_encoding = result.get('encoding', 'utf-8')
            
            self.logger.info(f"Encoding detectado: {detected_encoding} (confian√ßa: {confidence:.2f})")
            
            # Se confian√ßa baixa, tentar encodings comuns
            if confidence < 0.7:
                self.logger.warning(f"Baixa confian√ßa na detec√ß√£o de encoding ({confidence:.2f})")
                for encoding in self.supported_encodings:
                    try:
                        with open(file_path, 'r', encoding=encoding) as f:
                            f.read(1024)  # Teste de leitura
                        self.logger.info(f"Usando encoding alternativo: {encoding}")
                        return encoding
                    except UnicodeDecodeError:
                        continue
            
            return detected_encoding or 'utf-8'
            
        except Exception as e:
            self.logger.warning(f"Erro na detec√ß√£o de encoding: {str(e)}, usando utf-8")
            return 'utf-8'
    
    
    # M√©todo _create_fraud_data() removido - n√£o necess√°rio para MVP fiscal
    
    def _create_sales_data(self, num_rows: int, **kwargs) -> pd.DataFrame:
        """Gera dados sint√©ticos de vendas."""
        start_date = kwargs.get('start_date', '2023-01-01')
        
        # Gerar datas
        start = pd.to_datetime(start_date)
        dates = pd.date_range(start, periods=num_rows, freq='D')
        
        data = {
            'date': dates,
            'product_id': np.random.randint(1, 1000, num_rows),
            'category': np.random.choice(['electronics', 'clothing', 'books', 'home', 'sports'], num_rows),
            'price': np.random.uniform(10, 1000, num_rows),
            'quantity': np.random.randint(1, 10, num_rows),
            'sales_rep': np.random.choice([f'rep_{i:03d}' for i in range(1, 21)], num_rows),
            'region': np.random.choice(['North', 'South', 'East', 'West'], num_rows),
            'customer_type': np.random.choice(['new', 'returning', 'vip'], num_rows, p=[0.3, 0.6, 0.1])
        }
        
        data['total_amount'] = data['price'] * data['quantity']
        
        return pd.DataFrame(data)
    
    def _create_customer_data(self, num_rows: int, **kwargs) -> pd.DataFrame:
        """Gera dados sint√©ticos de clientes."""
        data = {
            'customer_id': range(1, num_rows + 1),
            'age': np.random.normal(35, 15, num_rows).astype(int).clip(18, 80),
            'income': np.random.lognormal(10, 0.5, num_rows).astype(int),
            'education': np.random.choice(['high_school', 'bachelor', 'master', 'phd'], num_rows, p=[0.3, 0.4, 0.2, 0.1]),
            'city_tier': np.random.choice([1, 2, 3], num_rows, p=[0.2, 0.3, 0.5]),
            'years_experience': np.random.exponential(5, num_rows).astype(int).clip(0, 40),
            'credit_score': np.random.normal(650, 100, num_rows).astype(int).clip(300, 850),
            'owns_home': np.random.choice([0, 1], num_rows, p=[0.4, 0.6]),
            'married': np.random.choice([0, 1], num_rows, p=[0.45, 0.55]),
        }
        
        # Correla√ß√µes realistas
        # Converter education para Series primeiro para usar map
        education_series = pd.Series(data['education'])
        education_multiplier = education_series.map({'high_school': 0, 'bachelor': 0.3, 'master': 0.6, 'phd': 1.0})
        data['income'] = data['income'] * (1 + education_multiplier)
        data['credit_score'] = data['credit_score'] + (data['income'] / 10000 * 20)
        
        return pd.DataFrame(data)
    
    def _create_generic_data(self, num_rows: int, **kwargs) -> pd.DataFrame:
        """Gera dados sint√©ticos gen√©ricos."""
        num_numeric = kwargs.get('num_numeric', 5)
        num_categorical = kwargs.get('num_categorical', 3)
        
        data = {}
        
        # Colunas num√©ricas
        for i in range(num_numeric):
            data[f'numeric_{i+1}'] = np.random.normal(100, 20, num_rows)
        
        # Colunas categ√≥ricas
        for i in range(num_categorical):
            categories = [f'cat_{j}' for j in range(1, np.random.randint(3, 8))]
            data[f'category_{i+1}'] = np.random.choice(categories, num_rows)
        
        # ID
        data['id'] = range(1, num_rows + 1)
        
        return pd.DataFrame(data)