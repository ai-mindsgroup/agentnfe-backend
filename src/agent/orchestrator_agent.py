"""Agente Orquestrador Central para coordenar sistema multiagente.

Este agente √© respons√°vel por:
- Receber consultas dos usu√°rios
- Determinar qual(is) agente(s) especializado(s) utilizar
- Coordenar m√∫ltiplos agentes quando necess√°rio
- Combinar respostas de diferentes agentes
- Manter contexto da conversa√ß√£o
- Fornecer interface √∫nica para o sistema completo
"""
from __future__ import annotations
import sys
import os
from pathlib import Path

# Adiciona o diret√≥rio raiz do projeto ao PYTHONPATH
root_dir = Path(__file__).parent.parent.parent
sys.path.insert(0, str(root_dir))

import re
from typing import Any, Dict, List, Optional, Union, Tuple
from dataclasses import dataclass
from enum import Enum

from src.agent.base_agent import BaseAgent, AgentError
from src.agent.csv_analysis_agent import CSVAnalysisAgent
from src.data.data_processor import DataProcessor

# Import condicional do RAGAgent (pode falhar se Supabase n√£o configurado)
try:
    from src.agent.rag_agent import RAGAgent
    RAG_AGENT_AVAILABLE = True
except ImportError as e:
    RAG_AGENT_AVAILABLE = False
    RAGAgent = None
    print(f"‚ö†Ô∏è RAGAgent n√£o dispon√≠vel: {str(e)[:100]}...")
except RuntimeError as e:
    RAG_AGENT_AVAILABLE = False  
    RAGAgent = None
    print(f"‚ö†Ô∏è RAGAgent n√£o dispon√≠vel: {str(e)[:100]}...")

# Import do cliente Supabase para verifica√ß√£o de dados
try:
    from src.vectorstore.supabase_client import supabase
    SUPABASE_CLIENT_AVAILABLE = True
except ImportError as e:
    SUPABASE_CLIENT_AVAILABLE = False
    supabase = None
    print(f"‚ö†Ô∏è Cliente Supabase n√£o dispon√≠vel: {str(e)[:100]}...")
except RuntimeError as e:
    SUPABASE_CLIENT_AVAILABLE = False
    supabase = None
    print(f"‚ö†Ô∏è Cliente Supabase n√£o dispon√≠vel: {str(e)[:100]}...")

# Import do LLM Manager (camada de abstra√ß√£o para m√∫ltiplos provedores)
try:
    from src.llm.manager import get_llm_manager, LLMManager, LLMConfig
    LLM_MANAGER_AVAILABLE = True
except ImportError as e:
    LLM_MANAGER_AVAILABLE = False
    print(f"‚ö†Ô∏è LLM Manager n√£o dispon√≠vel: {str(e)[:100]}...")
except RuntimeError as e:
    LLM_MANAGER_AVAILABLE = False
    print(f"‚ö†Ô∏è LLM Manager n√£o dispon√≠vel: {str(e)[:100]}...")

# Import do sistema de prompts
try:
    from src.prompts.manager import get_prompt_manager, AgentRole
    PROMPT_MANAGER_AVAILABLE = True
except ImportError as e:
    PROMPT_MANAGER_AVAILABLE = False
    print(f"‚ö†Ô∏è Prompt Manager n√£o dispon√≠vel: {str(e)[:100]}...")
except RuntimeError as e:
    PROMPT_MANAGER_AVAILABLE = False
    print(f"‚ö†Ô∏è Prompt Manager n√£o dispon√≠vel: {str(e)[:100]}...")


class QueryType(Enum):
    """Tipos de consultas que o orquestrador pode processar."""
    CSV_ANALYSIS = "csv_analysis"      # An√°lise de dados CSV
    RAG_SEARCH = "rag_search"          # Busca sem√¢ntica/contextual
    DATA_LOADING = "data_loading"      # Carregamento de dados
    LLM_ANALYSIS = "llm_analysis"      # An√°lise via LLM (Google Gemini)
    HYBRID = "hybrid"                  # M√∫ltiplos agentes necess√°rios
    GENERAL = "general"                # Consulta geral/conversacional
    UNKNOWN = "unknown"                # Tipo n√£o identificado


@dataclass
class AgentTask:
    """Representa uma tarefa para um agente espec√≠fico."""
    agent_name: str
    query: str
    context: Optional[Dict[str, Any]] = None
    priority: int = 1  # 1=alta, 2=m√©dia, 3=baixa


@dataclass
class OrchestratorResponse:
    """Resposta consolidada do orquestrador."""
    content: str
    query_type: QueryType
    agents_used: List[str]
    metadata: Dict[str, Any]
    success: bool = True
    error: Optional[str] = None


class OrchestratorAgent(BaseAgent):
    """Agente central que coordena todos os agentes especializados."""
    
    def __init__(self, 
                 enable_csv_agent: bool = True,
                 enable_rag_agent: bool = True,
                 enable_llm_manager: bool = True,
                 enable_data_processor: bool = True):
        """Inicializa o orquestrador com agentes especializados.
        
        Args:
            enable_csv_agent: Habilitar agente de an√°lise CSV
            enable_rag_agent: Habilitar agente RAG
            enable_llm_manager: Habilitar LLM Manager (camada de abstra√ß√£o para m√∫ltiplos LLMs)
            enable_data_processor: Habilitar processador de dados
        """
        super().__init__(
            name="orchestrator",
            description="Coordenador central do sistema multiagente de IA para an√°lise de dados"
        )
        
        # Inicializar agentes especializados
        self.agents = {}
        self.conversation_history = []
        self.current_data_context = {}
        
        # Inicializar LLM Manager (camada de abstra√ß√£o)
        self.llm_manager = None
        
        # Inicializar Prompt Manager
        self.prompt_manager = None
        if PROMPT_MANAGER_AVAILABLE:
            try:
                self.prompt_manager = get_prompt_manager()
                self.logger.info("‚úÖ Prompt Manager inicializado")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Falha ao inicializar Prompt Manager: {str(e)}")
        
        # Inicializar agentes com tratamento de erro gracioso
        initialization_errors = []
        
        # CSV Agent (sempre dispon√≠vel - sem depend√™ncias externas)
        if enable_csv_agent:
            try:
                self.agents["csv"] = CSVAnalysisAgent()
                self.logger.info("‚úÖ Agente CSV inicializado")
            except Exception as e:
                error_msg = f"CSV Agent: {str(e)}"
                initialization_errors.append(error_msg)
                self.logger.warning(f"‚ö†Ô∏è {error_msg}")
        
        # RAG Agent (requer Supabase configurado)
        if enable_rag_agent and RAG_AGENT_AVAILABLE:
            try:
                self.agents["rag"] = RAGAgent()
                self.logger.info("‚úÖ Agente RAG inicializado")
            except Exception as e:
                error_msg = f"RAG Agent: {str(e)}"
                initialization_errors.append(error_msg)
                self.logger.warning(f"‚ö†Ô∏è {error_msg}")
        elif enable_rag_agent and not RAG_AGENT_AVAILABLE:
            error_msg = "RAG Agent: Depend√™ncias n√£o dispon√≠veis (Supabase n√£o configurado)"
            initialization_errors.append(error_msg)
            self.logger.warning(f"‚ö†Ô∏è {error_msg}")

        # LLM Manager (camada de abstra√ß√£o para m√∫ltiplos provedores)
        if enable_llm_manager and LLM_MANAGER_AVAILABLE:
            try:
                self.llm_manager = get_llm_manager()
                self.logger.info("‚úÖ LLM Manager inicializado")
                
                # Adicionar informa√ß√µes do provedor ativo
                status = self.llm_manager.get_status()
                active_provider = status.get("active_provider", "unknown")
                self.logger.info(f"ü§ñ Provedor LLM ativo: {active_provider}")
                
            except Exception as e:
                error_msg = f"LLM Manager: {str(e)}"
                initialization_errors.append(error_msg)
                self.logger.warning(f"‚ö†Ô∏è {error_msg}")
        elif enable_llm_manager and not LLM_MANAGER_AVAILABLE:
            error_msg = "LLM Manager: Depend√™ncias n√£o dispon√≠veis"
            initialization_errors.append(error_msg)
            self.logger.warning(f"‚ö†Ô∏è {error_msg}")
        
        # Data Processor (sempre dispon√≠vel - sem depend√™ncias externas)  
        if enable_data_processor:
            try:
                self.data_processor = DataProcessor()
                self.logger.info("‚úÖ Data Processor inicializado")
            except Exception as e:
                error_msg = f"Data Processor: {str(e)}"
                initialization_errors.append(error_msg)
                self.logger.warning(f"‚ö†Ô∏è {error_msg}")
                self.data_processor = None
        else:
            self.data_processor = None
        
        # Log do resultado da inicializa√ß√£o
        if self.agents or self.data_processor:
            self.logger.info(f"üöÄ Orquestrador inicializado com {len(self.agents)} agentes")
            if initialization_errors:
                self.logger.warning(f"‚ö†Ô∏è {len(initialization_errors)} componentes falharam na inicializa√ß√£o")
        else:
            self.logger.error("‚ùå Nenhum agente foi inicializado com sucesso")
            if initialization_errors:
                raise AgentError(
                    self.name, 
                    f"Falha na inicializa√ß√£o de todos os componentes: {'; '.join(initialization_errors)}"
                )
    
    def process(self, query: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Processa consulta determinando agente(s) apropriado(s).
        
        Args:
            query: Consulta do usu√°rio
            context: Contexto adicional (file_path, dados, configura√ß√µes)
        
        Returns:
            Resposta consolidada do sistema
        """
        self.logger.info(f"üéØ Processando consulta: '{query[:50]}...'")
        
        try:
            # 1. Adicionar √† hist√≥ria da conversa
            self.conversation_history.append({
                "type": "user_query",
                "query": query,
                "timestamp": self._get_timestamp(),
                "context": context
            })
            
            # 2. Analisar tipo da consulta
            query_type = self._classify_query(query, context)
            self.logger.info(f"üìù Tipo de consulta identificado: {query_type.value}")
            
            # 3. Processar baseado no tipo
            if query_type == QueryType.CSV_ANALYSIS:
                result = self._handle_csv_analysis(query, context)
            elif query_type == QueryType.RAG_SEARCH:
                result = self._handle_rag_search(query, context)
            elif query_type == QueryType.DATA_LOADING:
                result = self._handle_data_loading(query, context)
            elif query_type == QueryType.LLM_ANALYSIS:
                result = self._handle_llm_analysis(query, context)
            elif query_type == QueryType.HYBRID:
                result = self._handle_hybrid_query(query, context)
            elif query_type == QueryType.GENERAL:
                result = self._handle_general_query(query, context)
            else:
                result = self._handle_unknown_query(query, context)
            
            # 4. Adicionar √† hist√≥ria
            self.conversation_history.append({
                "type": "system_response",
                "response": result,
                "timestamp": self._get_timestamp()
            })
            
            return result
            
        except Exception as e:
            self.logger.error(f"Erro no processamento: {str(e)}")
            return self._build_response(
                f"‚ùå Erro no processamento da consulta: {str(e)}",
                metadata={
                    "error": True,
                    "query_type": "error",
                    "agents_used": []
                }
            )
    
    def _check_data_availability(self) -> bool:
        """Verifica se h√° dados dispon√≠veis na base de dados.
        
        Returns:
            True se h√° dados carregados, False caso contr√°rio
        """
        # 1. Verificar contexto em mem√≥ria primeiro (mais r√°pido)
        if self.current_data_context.get("csv_loaded", False):
            self.logger.debug("‚úÖ Dados encontrados no contexto em mem√≥ria")
            return True
        
        # 2. Verificar dados na base de dados Supabase
        if SUPABASE_CLIENT_AVAILABLE and supabase:
            try:
                # Verificar se h√° dados na tabela embeddings
                result = supabase.table('embeddings').select('id').limit(1).execute()
                if result.data and len(result.data) > 0:
                    self.logger.debug("‚úÖ Dados encontrados na tabela embeddings")
                    # Atualizar contexto em mem√≥ria para pr√≥ximas consultas
                    self.current_data_context["csv_loaded"] = True
                    self.current_data_context["data_source"] = "database_embeddings"
                    return True
                
                # Verificar se h√° dados na tabela chunks
                result = supabase.table('chunks').select('id').limit(1).execute()
                if result.data and len(result.data) > 0:
                    self.logger.debug("‚úÖ Dados encontrados na tabela chunks")
                    # Atualizar contexto em mem√≥ria para pr√≥ximas consultas
                    self.current_data_context["csv_loaded"] = True
                    self.current_data_context["data_source"] = "database_chunks"
                    return True
                
                self.logger.debug("‚ùå Nenhum dado encontrado nas tabelas da base de dados")
                return False
                
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Erro ao verificar dados na base: {str(e)}")
                return False
        else:
            self.logger.debug("‚ö†Ô∏è Cliente Supabase n√£o dispon√≠vel")
            return False
    
    def _classify_query(self, query: str, context: Optional[Dict[str, Any]]) -> QueryType:
        """Classifica o tipo de consulta para roteamento adequado.
        
        Args:
            query: Consulta do usu√°rio
            context: Contexto adicional
        
        Returns:
            Tipo da consulta identificado
        """
        query_lower = query.lower()
        
        # Palavras-chave para cada tipo de consulta
        csv_keywords = [
            'csv', 'tabela', 'dados', 'an√°lise', 'estat√≠stica', 'correla√ß√£o',
            'gr√°fico', 'plot', 'visualiza√ß√£o', 'resumo', 'describe', 'dataset',
            'colunas', 'linhas', 'm√©dia', 'mediana', 'fraude', 'outlier'
        ]
        
        rag_keywords = [
            'buscar', 'procurar', 'encontrar', 'pesquisar', 'consultar',
            'conhecimento', 'base', 'documento', 'texto', 'similar',
            'contexto', 'embedding', 'sem√¢ntica', 'retrieval'
        ]
        
        data_keywords = [
            'carregar', 'upload', 'importar', 'abrir', 'arquivo',
            'dados sint√©ticos', 'gerar dados', 'criar dados', 'load'
        ]
        
        llm_keywords = [
            'explicar', 'explique', 'interpretar', 'interprete', 'insight', 'insights', 
            'conclus√£o', 'conclus√µes', 'recomenda√ß√£o', 'recomenda√ß√µes', 'recomende',
            'sugest√£o', 'sugest√µes', 'sugira', 'opini√£o', 'an√°lise detalhada', 
            'relat√≥rio', 'sum√°rio', 'resume', 'resumo detalhado', 'padr√£o', 'padr√µes', 
            'tend√™ncia', 'tend√™ncias', 'previs√£o', 'hip√≥tese', 'teoria', 'tire', 'conclua',
            'analise', 'avalie', 'considere', 'entenda', 'compreenda', 'descoberta',
            'descobrimentos', 'comportamento', 'anomalia', 'an√¥malo', 'suspeito',
            'detalhado', 'profundo', 'aprofunde', 'discuta', 'comente', 'o que',
            'quais', 'como', 'por que', 'porque'
        ]
        
        general_keywords = [
            'ol√°', 'oi', 'ajuda', 'como', 'o que', 'qual', 'quando',
            'onde', 'por que', 'definir', 'status', 'sistema'
        ]
        
        # Verificar contexto de arquivo
        has_file_context = context and 'file_path' in context
        
        # Classificar baseado em palavras-chave e contexto
        csv_score = sum(1 for kw in csv_keywords if kw in query_lower)
        rag_score = sum(1 for kw in rag_keywords if kw in query_lower)
        data_score = sum(1 for kw in data_keywords if kw in query_lower)
        llm_score = sum(3 for kw in llm_keywords if kw in query_lower)  # Peso triplicado para LLM
        general_score = sum(1 for kw in general_keywords if kw in query_lower)
        
        # Adicionar peso do contexto
        if has_file_context:
            if any(ext in str(context.get('file_path', '')).lower() for ext in ['.csv', '.xlsx', '.json']):
                csv_score += 1  # Reduzido para n√£o sobrepor LLM
        
        # Verificar se precisa de m√∫ltiplos agentes
        scores = [csv_score, rag_score, data_score, llm_score]
        high_scores = [s for s in scores if s >= 2]
        
        # Se LLM tem score alto, priorizar sobre hybrid
        if llm_score >= 3:
            return QueryType.LLM_ANALYSIS
        
        if len(high_scores) >= 2:
            return QueryType.HYBRID
        
        # Determinar tipo baseado na maior pontua√ß√£o
        max_score = max(csv_score, rag_score, data_score, llm_score, general_score)
        
        if max_score == 0:
            return QueryType.UNKNOWN
        elif max_score == csv_score:
            return QueryType.CSV_ANALYSIS
        elif max_score == rag_score:
            return QueryType.RAG_SEARCH
        elif max_score == data_score:
            return QueryType.DATA_LOADING
        elif max_score == llm_score:
            return QueryType.LLM_ANALYSIS
        else:
            return QueryType.GENERAL
    
    def _handle_csv_analysis(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """Delega an√°lise CSV para o agente especializado."""
        if "csv" not in self.agents:
            return self._build_response(
                "‚ùå Agente de an√°lise CSV n√£o est√° dispon√≠vel",
                metadata={"error": True, "agents_used": []}
            )
        
        self.logger.info("üìä Delegando para agente CSV")
        
        # Preparar contexto para o agente CSV
        csv_context = context or {}
        
        # Se h√° dados carregados no orquestrador, passar para o agente
        if self.current_data_context:
            csv_context.update(self.current_data_context)
        
        result = self.agents["csv"].process(query, csv_context)
        
        # Atualizar contexto se dados foram carregados
        if result.get("metadata") and not result["metadata"].get("error"):
            self.current_data_context.update(result["metadata"])
        
        return self._enhance_response(result, ["csv"])
    
    def _handle_rag_search(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """Delega busca sem√¢ntica para o agente RAG."""
        if "rag" not in self.agents:
            return self._build_response(
                "‚ùå Agente RAG n√£o est√° dispon√≠vel",
                metadata={"error": True, "agents_used": []}
            )
        
        self.logger.info("üîç Delegando para agente RAG")
        
        result = self.agents["rag"].process(query, context)
        return self._enhance_response(result, ["rag"])
    
    def _handle_data_loading(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """Processa carregamento de dados."""
        if not self.data_processor:
            return self._build_response(
                "‚ùå Sistema de carregamento de dados n√£o est√° dispon√≠vel",
                metadata={"error": True, "agents_used": []}
            )
        
        self.logger.info("üìÅ Processando carregamento de dados")
        
        try:
            # Verificar se foi fornecido um arquivo
            if context and 'file_path' in context:
                file_path = context['file_path']
                
                # Carregar dados usando DataProcessor
                result = self.data_processor.load_from_file(file_path)
                
                if not result.get('error'):
                    # Armazenar contexto dos dados carregados
                    self.current_data_context = {
                        'file_path': file_path,
                        'data_info': result.get('data_info', {}),
                        'quality_report': result.get('quality_report', {})
                    }
                    
                    # Criar resposta informativa
                    data_info = result.get('data_info', {})
                    quality_report = result.get('quality_report', {})
                    
                    response = f"""‚úÖ **Dados Carregados com Sucesso**

üìÑ **Arquivo:** {file_path}
üìä **Dimens√µes:** {data_info.get('rows', 0):,} linhas √ó {data_info.get('columns', 0)} colunas
‚≠ê **Qualidade:** {quality_report.get('overall_score', 0):.1f}/100

**Pr√≥ximos passos dispon√≠veis:**
‚Ä¢ An√°lise explorat√≥ria: "fa√ßa um resumo dos dados"
‚Ä¢ Correla√ß√µes: "mostre as correla√ß√µes"  
‚Ä¢ Visualiza√ß√µes: "crie gr√°ficos dos dados"
‚Ä¢ Busca sem√¢ntica: "busque informa√ß√µes sobre fraude"
"""
                    
                    return self._build_response(
                        response,
                        metadata={
                            "agents_used": ["data_processor"],
                            "data_loaded": True,
                            "file_path": file_path,
                            "data_info": data_info,
                            "quality_report": quality_report
                        }
                    )
                else:
                    return self._build_response(
                        f"‚ùå Erro ao carregar dados: {result.get('error', 'Erro desconhecido')}",
                        metadata={"error": True, "agents_used": ["data_processor"]}
                    )
            
            else:
                # Instru√ß√µes de como carregar dados
                response = """üìÅ **Como Carregar Dados**

Para carregar dados, use:
```
context = {"file_path": "caminho/para/seu/arquivo.csv"}
```

**Formatos suportados:**
‚Ä¢ CSV (.csv)
‚Ä¢ Excel (.xlsx) - *em desenvolvimento*
‚Ä¢ JSON (.json) - *em desenvolvimento*

**Dados sint√©ticos dispon√≠veis:**
‚Ä¢ Detec√ß√£o de fraude
‚Ä¢ Dados de vendas  
‚Ä¢ Dados de clientes
‚Ä¢ Dados gen√©ricos
"""
                
                return self._build_response(
                    response,
                    metadata={"agents_used": [], "instructions": True}
                )
        
        except Exception as e:
            self.logger.error(f"Erro no carregamento: {str(e)}")
            return self._build_response(
                f"‚ùå Erro no carregamento de dados: {str(e)}",
                metadata={"error": True, "agents_used": ["data_processor"]}
            )

    def _handle_llm_analysis(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """Processa consultas atrav√©s do LLM Manager com verifica√ß√£o de base de dados."""
        if not self.llm_manager:
            return self._build_response(
                "‚ùå LLM Manager n√£o est√° dispon√≠vel",
                metadata={"error": True, "agents_used": []}
            )
        
        self.logger.info("ü§ñ Delegando para LLM Manager")
        
        # 1. VERIFICA√á√ÉO OBRIGAT√ìRIA: Identificar se consulta requer dados espec√≠ficos
        data_specific_keywords = [
            'tipos de dados', 'colunas', 'vari√°veis', 'estat√≠sticas', 'resumo',
            'distribui√ß√£o', 'correla√ß√£o', 'missing', 'nulos', 'formato',
            'csv', 'arquivo', 'dataset', 'base de dados', 'planilha'
        ]
        
        needs_data_analysis = any(keyword in query.lower() for keyword in data_specific_keywords)
        
        # 2. VERIFICAR ESTADO DOS DADOS
        has_loaded_data = self._check_data_availability()
        has_file_context = bool(context and context.get("file_path"))
        
        self.logger.info(f"üìä An√°lise necess√°ria: {needs_data_analysis}, Dados carregados: {has_loaded_data}, Arquivo no contexto: {has_file_context}")
        
        # 3. L√ìGICA DE DECIS√ÉO BASEADA NO ESTADO
        if needs_data_analysis and not has_loaded_data and not has_file_context:
            # Caso 1: Precisa de dados espec√≠ficos mas n√£o h√° nada carregado
            return self._build_response(
                """‚ùì **Base de Dados Necess√°ria**
                
Sua pergunta requer an√°lise de dados espec√≠ficos, mas n√£o h√° nenhuma base de dados carregada no momento.

**Op√ß√µes dispon√≠veis:**

üî∏ **An√°lise espec√≠fica**: Carregue um arquivo CSV primeiro:
   ‚Ä¢ "carregar arquivo dados.csv"
   ‚Ä¢ "analisar arquivo /caminho/para/arquivo.csv"

üî∏ **Resposta gen√©rica**: Se deseja uma explica√ß√£o geral sobre o conceito, reformule sua pergunta:
   ‚Ä¢ "o que s√£o tipos de dados em geral?"
   ‚Ä¢ "explique conceitos b√°sicos de an√°lise de dados"

**Como posso te ajudar?**""",
                metadata={
                    "error": False, 
                    "agents_used": ["llm_manager"],
                    "requires_data": True,
                    "data_available": False
                }
            )
        
        elif needs_data_analysis and not has_loaded_data and has_file_context:
            # Caso 2: Precisa de dados, tem arquivo no contexto, mas n√£o carregou ainda
            self.logger.info("üîÑ Carregando dados automaticamente para an√°lise espec√≠fica...")
            
            # Tentar carregar dados usando agente CSV
            if "csv" in self.agents:
                try:
                    load_query = f"carregar e analisar estrutura b√°sica"
                    csv_result = self.agents["csv"].process(load_query, context)
                    
                    if csv_result and not csv_result.get("metadata", {}).get("error", False):
                        # Extrair informa√ß√µes do CSV e atualizar contexto
                        self._update_data_context_from_csv_result(csv_result, context)
                        self.logger.info("‚úÖ Dados carregados automaticamente")
                    else:
                        return self._build_response(
                            f"‚ùå N√£o foi poss√≠vel carregar o arquivo: {csv_result.get('content', 'Erro desconhecido')}",
                            metadata={"error": True, "agents_used": ["csv"]}
                        )
                except Exception as e:
                    return self._build_response(
                        f"‚ùå Erro ao carregar arquivo: {str(e)}",
                        metadata={"error": True, "agents_used": ["csv"]}
                    )
            else:
                return self._build_response(
                    "‚ùå Agente CSV n√£o dispon√≠vel para carregar dados",
                    metadata={"error": True, "agents_used": []}
                )
        
        # 4. PREPARAR CONTEXTO PARA LLM
        llm_context = context.copy() if context else {}
        
        # Adicionar dados carregados se dispon√≠veis
        if self.current_data_context:
            llm_context.update(self.current_data_context)
        
        # 5. CONSTRUIR PROMPT CONTEXTUALIZADO
        prompt = self._build_llm_prompt(query, llm_context, needs_data_analysis)
        
        try:
            # 6. CHAMAR LLM MANAGER
            config = LLMConfig(temperature=0.2, max_tokens=1024)
            response = self.llm_manager.chat(prompt, config)
            
            if not response.success:
                raise RuntimeError(response.error)
            
            # 7. CONSTRUIR RESPOSTA COM METADADOS CORRETOS
            result = {
                "content": response.content,
                "metadata": {
                    "provider": response.provider.value,
                    "model": response.model,
                    "processing_time": response.processing_time,
                    "tokens_used": response.tokens_used,
                    "data_analysis": needs_data_analysis,
                    "data_loaded": bool(self.current_data_context.get("csv_loaded", False))
                }
            }
            
            # 8. REGISTRAR AGENTES USADOS CORRETAMENTE
            agents_used = ["llm_manager"]
            if needs_data_analysis and self.current_data_context.get("csv_loaded"):
                agents_used.append("csv")  # CSV foi usado para carregar dados
            
            return self._enhance_response(result, agents_used)
            
        except Exception as e:
            self.logger.error(f"Erro no LLM Manager: {str(e)}")
            return self._build_response(
                f"‚ùå Erro na an√°lise LLM: {str(e)}",
                metadata={"error": True, "agents_used": ["llm_manager"]}
            )
    
    def _handle_hybrid_query(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """Processa consultas que requerem m√∫ltiplos agentes."""
        self.logger.info("üîÑ Processando consulta h√≠brida (m√∫ltiplos agentes)")
        
        results = []
        agents_used = []
        
        # Determinar quais agentes s√£o necess√°rios
        query_lower = query.lower()
        
        # CSV + RAG (ex: "analise os dados e busque informa√ß√µes similares")
        if any(kw in query_lower for kw in ['dados', 'csv', 'an√°lise']) and \
           any(kw in query_lower for kw in ['buscar', 'similar', 'contexto']):
            
            # Primeiro: an√°lise CSV se h√° dados
            if "csv" in self.agents and self.current_data_context:
                csv_result = self.agents["csv"].process(query, context)
                results.append(("csv", csv_result))
                agents_used.append("csv")
            
            # Segundo: busca RAG
            if "rag" in self.agents:
                rag_result = self.agents["rag"].process(query, context)
                results.append(("rag", rag_result))
                agents_used.append("rag")
        
        # Se nenhum resultado, usar abordagem padr√£o
        if not results:
            return self._handle_csv_analysis(query, context)
        
        # Combinar resultados
        combined_response = self._combine_agent_responses(results)
        
        return self._build_response(
            combined_response,
            metadata={"agents_used": agents_used, "hybrid_query": True}
        )
    
    def _handle_general_query(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """Processa consultas gerais/conversacionais."""
        self.logger.info("üí¨ Processando consulta geral")
        
        query_lower = query.lower()
        
        # Sauda√ß√µes
        if any(greeting in query_lower for greeting in ['ol√°', 'oi', 'ola']):
            response = """üëã **Ol√°! Sou o Orquestrador do Sistema EDA AI Minds**

Sou o coordenador central que pode te ajudar com:

üîç **An√°lise de Dados CSV**
‚Ä¢ Carregamento e valida√ß√£o de arquivos
‚Ä¢ Estat√≠sticas e correla√ß√µes  
‚Ä¢ Visualiza√ß√µes e insights

üß† **Busca Sem√¢ntica (RAG)**
‚Ä¢ Consultas contextualizadas
‚Ä¢ Base de conhecimento vetorial
‚Ä¢ Respostas inteligentes

**Como posso te ajudar hoje?**
"""
            return self._build_response(response, metadata={"agents_used": [], "greeting": True})
        
        # Status do sistema
        elif any(status in query_lower for status in ['status', 'sistema', 'agentes']):
            return self._get_system_status()
        
        # Ajuda
        elif 'ajuda' in query_lower or 'help' in query_lower:
            return self._get_help_response()
        
        # Usar LLM Manager para resposta geral se dispon√≠vel
        elif self.llm_manager:
            try:
                prompt = self._build_llm_prompt(query, context)
                config = LLMConfig(temperature=0.3, max_tokens=512)  # Mais criativo para consultas gerais
                response = self.llm_manager.chat(prompt, config)
                
                if response.success:
                    result = {"content": response.content}
                    return self._enhance_response(result, ["llm_manager"])
                else:
                    raise RuntimeError(response.error)
                    
            except Exception as e:
                self.logger.warning(f"Erro ao usar LLM Manager para consulta geral: {str(e)}")
                # Fallback para resposta padr√£o
                response = "Desculpe, n√£o consegui processar sua consulta com o LLM. Tente ser mais espec√≠fico ou pergunte sobre an√°lise de dados CSV."
                return self._build_response(response, metadata={"agents_used": [], "fallback": True})
        
        # Resposta padr√£o quando LLM n√£o est√° dispon√≠vel
        else:
            response = """üí≠ **Consulta Geral Recebida**

Como n√£o tenho acesso ao LLM no momento, posso te ajudar especificamente com:

üìä **An√°lise de Dados CSV:**
‚Ä¢ "analise o arquivo dados.csv"
‚Ä¢ "mostre correla√ß√µes"
‚Ä¢ "detecte fraudes"

üîç **Carregamento de Dados:**  
‚Ä¢ "carregue o arquivo X"
‚Ä¢ "valide os dados"

**Tente ser mais espec√≠fico sobre dados ou an√°lises!**
"""
            return self._build_response(response, metadata={"agents_used": [], "general_query": True})
    
    def _handle_unknown_query(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """Processa consultas de tipo desconhecido."""
        self.logger.warning(f"ü§î Consulta de tipo desconhecido: {query[:50]}...")
        
        response = f"""ü§î **N√£o consegui identificar o tipo da sua consulta**

**Sua consulta:** "{query}"

**Posso te ajudar com:**
‚Ä¢ üìä **An√°lise de dados:** "analise o arquivo dados.csv"
‚Ä¢ üîç **Busca sem√¢ntica:** "busque informa√ß√µes sobre fraude"
‚Ä¢ üìÅ **Carregar dados:** use context={{"file_path": "arquivo.csv"}}

**Reformule sua pergunta ou seja mais espec√≠fico sobre o que precisa.**
"""
        
        return self._build_response(response, metadata={"agents_used": [], "unknown_query": True})
    
    def _combine_agent_responses(self, results: List[Tuple[str, Dict[str, Any]]]) -> str:
        """Combina respostas de m√∫ltiplos agentes em uma resposta coesa."""
        if not results:
            return "Nenhum resultado dispon√≠vel."
        
        combined = "üîÑ **Resposta Consolidada de M√∫ltiplos Agentes**\n\n"
        
        for agent_name, result in results:
            agent_display = {
                "csv": "üìä **An√°lise CSV**",
                "rag": "üîç **Busca Sem√¢ntica**"
            }.get(agent_name, f"ü§ñ **{agent_name.upper()}**")
            
            combined += f"{agent_display}\n"
            combined += f"{result.get('content', 'Sem conte√∫do')}\n\n"
            combined += "‚îÄ" * 50 + "\n\n"
        
        return combined.rstrip("‚îÄ\n ")
    
    def _enhance_response(self, agent_result: Dict[str, Any], agents_used: List[str]) -> Dict[str, Any]:
        """Melhora resposta do agente com informa√ß√µes do orquestrador."""
        if not agent_result:
            return self._build_response("Erro: resposta vazia do agente", metadata={"error": True})
        
        # Preservar conte√∫do original
        enhanced = agent_result.copy()
        
        # Adicionar informa√ß√µes do orquestrador
        if "metadata" not in enhanced:
            enhanced["metadata"] = {}
        
        # CORRE√á√ÉO: Registrar agentes usados no n√≠vel principal da metadata
        enhanced["metadata"]["agents_used"] = agents_used
        enhanced["metadata"]["orchestrator"] = {
            "conversation_length": len(self.conversation_history),
            "has_data_context": bool(self.current_data_context)
        }
        
        return enhanced
    
    def _get_system_status(self) -> Dict[str, Any]:
        """Retorna status completo do sistema."""
        status_info = {
            "agents": {},
            "data_context": bool(self.current_data_context),
            "conversation_history": len(self.conversation_history)
        }
        
        # Status dos agentes
        for name, agent in self.agents.items():
            status_info["agents"][name] = {
                "available": True,
                "name": agent.name,
                "description": agent.description
            }
        
        # Status do data processor
        if self.data_processor:
            status_info["data_processor"] = {"available": True}
        
        # Informa√ß√µes sobre dados carregados
        data_info = ""
        if self.current_data_context:
            file_path = self.current_data_context.get('file_path', 'N/A')
            data_info = f"\nüìÅ **Dados Carregados:** {file_path}"
        
        response = f"""‚ö° **Status do Sistema EDA AI Minds**

ü§ñ **Agentes Dispon√≠veis:** {len(self.agents)}
{chr(10).join(f'‚Ä¢ {name.upper()}: {agent.description}' for name, agent in self.agents.items())}

üíæ **Data Processor:** {'‚úÖ Ativo' if self.data_processor else '‚ùå Inativo'}
üí¨ **Hist√≥rico:** {len(self.conversation_history)} intera√ß√µes{data_info}

üöÄ **Sistema Operacional e Pronto!**
"""
        
        return self._build_response(response, metadata=status_info)
    
    def _get_help_response(self) -> Dict[str, Any]:
        """Retorna informa√ß√µes de ajuda completas."""
        help_text = """üìö **Guia de Uso do Sistema EDA AI Minds**

## üîç **Tipos de Consulta**

### üìä **An√°lise de Dados CSV**
```python
# Carregar arquivo
context = {"file_path": "dados.csv"}
query = "carregue os dados"

# An√°lises
"fa√ßa um resumo dos dados"
"mostre as correla√ß√µes"
"analise fraudes"
"crie visualiza√ß√µes"
```

### üß† **Busca Sem√¢ntica (RAG)**
```python
"busque informa√ß√µes sobre detec√ß√£o de fraude"
"encontre dados similares a transa√ß√µes suspeitas"
"qual o contexto sobre an√°lise de risco?"
```

### üìÅ **Carregamento de Dados**
```python
"carregar arquivo CSV"
"importar dados"
"gerar dados sint√©ticos"
```

## üí° **Dicas**
‚Ä¢ Seja espec√≠fico nas consultas
‚Ä¢ Use contexto para fornecer arquivos
‚Ä¢ Combine diferentes tipos de an√°lise
‚Ä¢ Pergunte sobre status do sistema

**Exemplo Completo:**
```python
# 1. Carregar dados
context = {"file_path": "fraude.csv"}
"carregue e analise os dados"

# 2. An√°lise espec√≠fica  
"mostre correla√ß√µes entre valor e fraude"

# 3. Busca contextual
"busque padr√µes similares na base de conhecimento"
```
"""
        
        return self._build_response(help_text, metadata={"help": True, "agents_used": []})
    
    def get_conversation_history(self) -> List[Dict[str, Any]]:
        """Retorna hist√≥rico completo da conversa."""
        return self.conversation_history.copy()
    
    def clear_conversation_history(self) -> Dict[str, Any]:
        """Limpa hist√≥rico da conversa."""
        count = len(self.conversation_history)
        self.conversation_history.clear()
        self.logger.info(f"Hist√≥rico limpo: {count} intera√ß√µes removidas")
        
        return self._build_response(
            f"‚úÖ Hist√≥rico limpo: {count} intera√ß√µes removidas",
            metadata={"cleared_count": count}
        )
    
    def clear_data_context(self) -> Dict[str, Any]:
        """Limpa contexto de dados carregados."""
        if self.current_data_context:
            file_path = self.current_data_context.get('file_path', 'N/A')
            self.current_data_context.clear()
            self.logger.info(f"Contexto de dados limpo: {file_path}")
            
            return self._build_response(
                f"‚úÖ Contexto de dados limpo: {file_path}",
                metadata={"cleared_data": file_path}
            )
        else:
            return self._build_response(
                "‚ÑπÔ∏è Nenhum contexto de dados para limpar",
                metadata={"no_data_context": True}
            )
    
    def _update_data_context_from_csv_result(self, csv_result: Dict[str, Any], context: Dict[str, Any]) -> None:
        """Atualiza contexto de dados com resultado da an√°lise CSV."""
        try:
            csv_content = csv_result.get("content", "")
            
            # Extrair informa√ß√µes b√°sicas do resultado CSV
            data_info = {
                "file_path": context.get("file_path", ""),
                "csv_loaded": True,
                "structure_analyzed": True,
                "csv_analysis": csv_content
            }
            
            # Tentar extrair informa√ß√µes espec√≠ficas do conte√∫do
            if "Colunas:" in csv_content:
                # Extrair lista de colunas se dispon√≠vel
                lines = csv_content.split('\n')
                for i, line in enumerate(lines):
                    if "Colunas:" in line and i + 1 < len(lines):
                        columns_info = lines[i + 1].strip()
                        data_info["columns_summary"] = columns_info
                        break
            
            if "Shape:" in csv_content:
                # Extrair informa√ß√µes de shape
                lines = csv_content.split('\n')
                for line in lines:
                    if "Shape:" in line:
                        shape_info = line.replace("Shape:", "").strip()
                        data_info["shape"] = shape_info
                        break
            
            # Atualizar contexto global
            self.current_data_context.update(data_info)
            self.logger.info(f"‚úÖ Contexto de dados atualizado: {data_info['file_path']}")
            
        except Exception as e:
            self.logger.error(f"Erro ao atualizar contexto de dados: {e}")

    def get_available_agents(self) -> Dict[str, Any]:
        """Retorna informa√ß√µes sobre agentes dispon√≠veis."""
        agents_info = {}
        
        for name, agent in self.agents.items():
            agents_info[name] = {
                "name": agent.name,
                "description": agent.description,
                "class": agent.__class__.__name__
            }
        
        response = "ü§ñ **Agentes Dispon√≠veis**\n\n"
        for name, info in agents_info.items():
            response += f"‚Ä¢ **{name.upper()}**: {info['description']}\n"
        
        return self._build_response(response, metadata={"agents": agents_info})

    def _build_llm_prompt(self, query: str, context: Optional[Dict[str, Any]] = None, needs_data_analysis: bool = False) -> Tuple[str, Optional[str]]:
        """Constr√≥i prompt contextualizado para o LLM Manager.
        
        Args:
            query: Consulta do usu√°rio
            context: Contexto adicional (dados, hist√≥rico, etc.)
            needs_data_analysis: Se a consulta requer an√°lise de dados espec√≠ficos
            
        Returns:
            Tuple[str, Optional[str]]: (user_prompt, system_prompt)
        """
        prompt_parts = []
        
        # Instru√ß√£o base diferenciada
        if needs_data_analysis and context and context.get("csv_loaded"):
            prompt_parts.append("""Voc√™ √© um assistente especializado em an√°lise de dados CSV.
Responda com base ESPECIFICAMENTE nos dados carregados fornecidos no contexto.
Use portugu√™s brasileiro e seja preciso e detalhado sobre os dados reais.""")
        else:
            prompt_parts.append("""Voc√™ √© um assistente de an√°lise de dados especializado em CSV e an√°lise estat√≠stica.
Responda de forma clara, precisa e √∫til. Use portugu√™s brasileiro.""")
        
        # Adicionar contexto de dados se dispon√≠vel
        if context:
            if 'file_path' in context:
                prompt_parts.append(f"\nüìä ARQUIVO CARREGADO: {context['file_path']}")
            
            if 'csv_analysis' in context:
                prompt_parts.append(f"\nüìà AN√ÅLISE DOS DADOS:\n{context['csv_analysis']}")
                
            if 'columns_summary' in context:
                prompt_parts.append(f"\nüìã COLUNAS: {context['columns_summary']}")
                
            if 'shape' in context:
                prompt_parts.append(f"\nÔøΩ DIMENS√ïES: {context['shape']}")
        
        # Adicionar a consulta do usu√°rio
        prompt_parts.append(f"\n‚ùì CONSULTA DO USU√ÅRIO: {query}")
        
        # Instru√ß√£o final diferenciada
        if needs_data_analysis and context and context.get("csv_loaded"):
            prompt_parts.append("""\nüéØ INSTRU√á√ïES:
- Analise SOMENTE os dados espec√≠ficos carregados
- Seja preciso sobre as colunas, tipos e estat√≠sticas REAIS
- N√ÉO d√™ respostas gen√©ricas sobre conceitos
- Forne√ßa uma resposta baseada nos dados concretos""")
        else:
            prompt_parts.append("\nüéØ Forne√ßa uma resposta √∫til e estruturada:")
        
        return "\n".join(prompt_parts)