# ğŸš¨ AUDITORIA CRÃTICA DE GUARDRAILS - Sistema EDA AI Minds

**Data:** 2025-11-06  
**Analista:** GitHub Copilot  
**Severidade:** ğŸ”´ CRÃTICA - ViolaÃ§Ãµes de SeguranÃ§a e Privacidade Detectadas

---

## ğŸ“‹ RESUMO EXECUTIVO

O sistema apresenta **MÃšLTIPLAS VIOLAÃ‡Ã•ES** dos guardrails de seguranÃ§a definidos, permitindo:
1. âŒ ExposiÃ§Ã£o de nomes de tabelas internas (`embeddings`, `agent_context`)
2. âŒ ExposiÃ§Ã£o de estrutura tÃ©cnica de banco de dados
3. âŒ Respostas extremamente longas (>500 palavras quando deveria ser 2-4 parÃ¡grafos curtos)
4. âŒ InformaÃ§Ãµes tÃ©cnicas nÃ£o solicitadas pelo usuÃ¡rio
5. âŒ Falha em proteger metadados do sistema

---

## ğŸ” ANÃLISE DETALHADA

### 1. RESPOSTA PROBLEMÃTICA ANALISADA

**Pergunta do UsuÃ¡rio:** "Sobre o que Ã© o dataset?"

**Resposta Gerada (Resumo das ViolaÃ§Ãµes):**
```
"O dataset fornecido Ã© um conjunto de dados estruturados, representado por um 
DataFrame, que foi reconstruÃ­do a partir da coluna `chunk_text` da tabela 
`embeddings`. As estatÃ­sticas fornecidas refletem os dados reais, nÃ£o a estrutura 
da tabela `embeddings`."
```

**Problemas Identificados:**
- âŒ Mencionou explicitamente `tabela embeddings`
- âŒ Mencionou campo `chunk_text`
- âŒ ExpÃ´s arquitetura interna (DataFrame reconstruÃ­do)
- âŒ Resposta com >300 palavras (deveria ser 2-4 parÃ¡grafos curtos)
- âŒ Listou "VARIÃVEIS NUMÃ‰RICAS" e "VARIÃVEIS CATEGÃ“RICAS" vazias
- âŒ Forneceu estrutura tÃ©cnica do sistema

---

### 2. GUARDRAILS VIOLADOS

#### âœ… Guardrails Definidos no `orchestrator_agent.py` (linhas 1571-1600):

```python
ğŸ›¡ï¸ GUARDRAILS OBRIGATÃ“RIOS (SeguranÃ§a e Privacidade):
1) Somente leitura: nÃ£o crie, altere, exclua ou atualize dados, tabelas, Ã­ndices, 
   views ou arquivos.

2) NÃ£o revele informaÃ§Ãµes sensÃ­veis: NUNCA INFORME nomes de tabelas internas, 
   senhas, chaves de API, tokens, DSNs, strings de conexÃ£o, caminhos/paths de 
   arquivos, diretÃ³rios do sistema, variÃ¡veis de ambiente, IPs, provedores de 
   hospedagem, configuraÃ§Ãµes do servidor ou detalhes do ambiente de desenvolvimento.

3) NÃ£o compartilhe dados confidenciais/pessoais; quando necessÃ¡rio, responda com 
   agregados ou exemplos genÃ©ricos.

6) Nunca finja executar aÃ§Ãµes de escrita (DELETE/INSERT/UPDATE/MIGRATE). Nunca 
   prometa alterar o banco ou arquivos.
```

**Status:** ğŸ”´ VIOLADO - Guardrail #2 completamente ignorado

---

### 3. ORIGEM DO PROBLEMA

#### Arquivo: `src/agent/rag_data_agent.py`

**Linha 354-368: System Prompt SEM Guardrails**

```python
system_prompt = """
VocÃª Ã© um agente EDA especializado. Sua tarefa Ã© apresentar resultados 
analÃ­ticos de forma clara e estruturada.

VocÃª receberÃ¡:
1. Pergunta do usuÃ¡rio
2. Resultados de anÃ¡lises executadas (JSON estruturado)
3. Chunks analÃ­ticos do CSV (contexto adicional)
4. HistÃ³rico conversacional (se houver)

Sua resposta deve:
- Iniciar com: "Pergunta feita: [pergunta]"
- Apresentar resultados de forma humanizada e estruturada
- Usar tabelas Markdown quando apropriado
- Destacar insights relevantes
- Finalizar com: "Se precisar de mais detalhes, Ã© sÃ³ perguntar!"
"""
```

**Problemas:**
- âŒ ZERO menÃ§Ã£o a guardrails de seguranÃ§a
- âŒ NÃ£o proÃ­be exposiÃ§Ã£o de tabelas/campos
- âŒ NÃ£o limita tamanho de resposta
- âŒ NÃ£o instrui sobre proteÃ§Ã£o de metadados
- âŒ Permite resposta tÃ©cnica sobre estrutura interna

---

### 4. ANÃLISE DO FLUXO DE ROTEAMENTO

**ClassificaÃ§Ã£o da Query:** "Sobre o que Ã© o dataset?"

1. **orchestrator_agent.py** â†’ `_classify_query()` â†’ detecta `QueryType.CSV_ANALYSIS`
2. **orchestrator_agent.py** â†’ `_handle_csv_analysis()` â†’ delega para `RAGDataAgent`
3. **rag_data_agent.py** â†’ `process()` â†’ executa anÃ¡lise
4. **rag_data_agent.py** â†’ `_synthesize_response()` (linha 350-410) â†’ **FALHA AQUI**

**Ponto de Falha:** O `RAGDataAgent` NÃƒO recebe nem aplica os guardrails do `OrchestratorAgent`

---

### 5. VERIFICAÃ‡ÃƒO DE MIGRATIONS (Estrutura de Dados)

**Migration `0002_schema.sql` - Tabela embeddings:**

```sql
create table if not exists public.embeddings (
    id uuid primary key default gen_random_uuid(),
    chunk_text text not null,
    embedding vector(1536) not null,
    metadata jsonb default '{}'::jsonb,
    created_at timestamp with time zone default now()
);
```

**ObservaÃ§Ã£o:**
- âœ… A tabela `embeddings` Ã© GENÃ‰RICA (nÃ£o especÃ­fica para NFe)
- âœ… O campo `metadata` armazena informaÃ§Ãµes do domÃ­nio (NFe, transaÃ§Ãµes, etc)
- âš ï¸ O sistema DEVE inferir o domÃ­nio via LLM analisando `metadata`, NÃƒO expor estrutura

---

### 6. MÃ‰TODO `_get_dataset_info()` - ANÃLISE

**LocalizaÃ§Ã£o:** `orchestrator_agent.py`, linhas 2008-2050

**ImplementaÃ§Ã£o Atual (Corrigida Anteriormente):**
```python
def _get_dataset_info(self) -> str:
    """ObtÃ©m informaÃ§Ãµes sobre o dataset atravÃ©s da LLM, sem hardcode."""
    
    # Buscar amostra de metadata
    result = supabase.table('embeddings').select('metadata').limit(5).execute()
    
    # LLM analisa e descreve de forma segura
    prompt = f"""Analise esta amostra de metadados e descreva o tipo de dataset 
    de forma GENÃ‰RICA e SEGURA.

    REGRAS OBRIGATÃ“RIAS:
    - NÃƒO mencione nomes de tabelas, campos, colunas ou arquivos
    - NÃƒO exponha estrutura tÃ©cnica ou paths
    - Descreva apenas o DOMÃNIO/TEMA dos dados
    - Seja breve (mÃ¡ximo 1 frase)
    """
```

**Status:** âœ… CORRETO - MÃ©todo protege estrutura via prompt para LLM

---

### 7. PROBLEMA CRÃTICO: `RAGDataAgent` IGNORA GUARDRAILS

#### System Prompts no RAGDataAgent:

**Prompt 1 (linha 354):** Sem guardrails  
**Prompt 2 (linha 440):** "VocÃª Ã© um agente EDA. Responda Ã  pergunta usando os chunks fornecidos." - Sem guardrails  
**Prompt 3 (linha 1259):** Sem guardrails especÃ­ficos de proteÃ§Ã£o

**ConsequÃªncia:**
Quando `OrchestratorAgent` delega para `RAGDataAgent`, os guardrails NÃƒO sÃ£o propagados.

---

## ğŸ¯ RECOMENDAÃ‡Ã•ES CRÃTICAS

### âœ… AÃ‡ÃƒO IMEDIATA NECESSÃRIA

#### 1. **Adicionar Guardrails Globais ao RAGDataAgent**

Criar mÃ©todo centralizado que SEMPRE aplica guardrails:

```python
def _get_security_guardrails(self) -> str:
    """Retorna string de guardrails obrigatÃ³rios para TODOS os prompts."""
    return """
ğŸ›¡ï¸ GUARDRAILS OBRIGATÃ“RIOS:
- NUNCA mencione nomes de tabelas (embeddings, chunks, metadata, agent_*)
- NUNCA exponha campos/colunas do banco de dados
- NUNCA revele paths, configuraÃ§Ãµes, estrutura tÃ©cnica interna
- Respostas BREVES: 2-4 parÃ¡grafos curtos (mÃ¡ximo 200 palavras)
- EXCEÃ‡ÃƒO: anÃ¡lises estatÃ­sticas podem ser mais longas quando necessÃ¡rio
- Descreva domÃ­nio/tema dos dados de forma genÃ©rica
- Exemplo BOM: "Este dataset contÃ©m informaÃ§Ãµes fiscais"
- Exemplo RUIM: "Tabela embeddings com campo chunk_text contÃ©m..."
"""
```

#### 2. **Refatorar TODOS os System Prompts**

Modificar `rag_data_agent.py` linhas 354, 440, 1259 para incluir:

```python
system_prompt = f"""
VocÃª Ã© um agente EDA especializado.

{self._get_security_guardrails()}

[... resto do prompt especÃ­fico ...]
"""
```

#### 3. **ValidaÃ§Ã£o PÃ³s-GeraÃ§Ã£o (Guardrail Enforcement)**

Adicionar mÃ©todo de validaÃ§Ã£o apÃ³s LLM gerar resposta:

```python
def _validate_response_security(self, response: str) -> str:
    """Valida resposta e sanitiza exposiÃ§Ãµes acidentais."""
    
    # Lista de termos proibidos
    forbidden_terms = [
        'embeddings', 'chunks', 'metadata', 'agent_sessions',
        'agent_conversations', 'agent_context', 'chunk_text',
        'embedding vector', 'supabase', 'postgres', 'tabela'
    ]
    
    # Detectar violaÃ§Ãµes
    violations = [term for term in forbidden_terms if term.lower() in response.lower()]
    
    if violations:
        self.logger.error(f"ğŸš¨ VIOLAÃ‡ÃƒO DE GUARDRAILS: {violations}")
        # ForÃ§ar LLM a reescrever de forma genÃ©rica
        return self._regenerate_secure_response(response)
    
    return response
```

#### 4. **Limitar Tamanho de Resposta**

Adicionar validaÃ§Ã£o de comprimento:

```python
def _enforce_response_length(self, response: str, max_words: int = 200) -> str:
    """Garante resposta breve conforme guardrails."""
    
    words = response.split()
    if len(words) > max_words:
        self.logger.warning(f"âš ï¸ Resposta muito longa: {len(words)} palavras (limite: {max_words})")
        # Truncar ou pedir LLM resumir
        return self._llm_summarize(response, max_words)
    
    return response
```

---

## ğŸ“Š MÃ‰TRICAS DE SEGURANÃ‡A

### Estado Atual (ANTES da CorreÃ§Ã£o):

| MÃ©trica | Status | Severidade |
|---------|--------|-----------|
| ExposiÃ§Ã£o de tabelas | âŒ FALHA | ğŸ”´ CRÃTICA |
| ExposiÃ§Ã£o de campos | âŒ FALHA | ğŸ”´ CRÃTICA |
| Tamanho de resposta | âŒ FALHA | ğŸŸ¡ MÃ‰DIA |
| ProteÃ§Ã£o de metadados | âŒ FALHA | ğŸ”´ CRÃTICA |
| PropagaÃ§Ã£o de guardrails | âŒ FALHA | ğŸ”´ CRÃTICA |
| **Score Geral** | **20%** | ğŸ”´ REPROVADO |

### Estado Esperado (APÃ“S CorreÃ§Ã£o):

| MÃ©trica | Status | Severidade |
|---------|--------|-----------|
| ExposiÃ§Ã£o de tabelas | âœ… OK | ğŸŸ¢ SEGURO |
| ExposiÃ§Ã£o de campos | âœ… OK | ğŸŸ¢ SEGURO |
| Tamanho de resposta | âœ… OK | ğŸŸ¢ SEGURO |
| ProteÃ§Ã£o de metadados | âœ… OK | ğŸŸ¢ SEGURO |
| PropagaÃ§Ã£o de guardrails | âœ… OK | ğŸŸ¢ SEGURO |
| **Score Geral** | **100%** | ğŸŸ¢ APROVADO |

---

## ğŸ”§ PLANO DE IMPLEMENTAÃ‡ÃƒO

### Fase 1: CorreÃ§Ã£o Imediata (URGENTE)
- [ ] Adicionar `_get_security_guardrails()` ao `RAGDataAgent`
- [ ] Refatorar system prompts (linhas 354, 440, 1259)
- [ ] Adicionar validaÃ§Ã£o pÃ³s-geraÃ§Ã£o `_validate_response_security()`
- [ ] Implementar limite de tamanho `_enforce_response_length()`

### Fase 2: Testes e ValidaÃ§Ã£o
- [ ] Testar query: "Sobre o que Ã© o dataset?"
- [ ] Validar que resposta NÃƒO menciona tabelas/campos
- [ ] Validar resposta breve (2-4 parÃ¡grafos)
- [ ] Testar outras queries que possam expor estrutura

### Fase 3: DocumentaÃ§Ã£o
- [ ] Atualizar documentaÃ§Ã£o de seguranÃ§a
- [ ] Criar guia de guardrails para novos agentes
- [ ] Adicionar testes automatizados de seguranÃ§a

---

## ğŸ“ CONCLUSÃƒO

**SituaÃ§Ã£o CrÃ­tica Identificada:**
O sistema atual **NÃƒO GARANTE** a seguranÃ§a dos dados conforme especificado nos guardrails. 

**Risco:**
ExposiÃ§Ã£o de arquitetura interna, estrutura de banco de dados e metadados sensÃ­veis.

**AÃ§Ã£o Requerida:**
ImplementaÃ§Ã£o **IMEDIATA** das correÃ§Ãµes propostas antes de qualquer deploy em produÃ§Ã£o.

**Prioridade:** ğŸ”´ CRÃTICA  
**Prazo Recomendado:** Implementar correÃ§Ãµes nas prÃ³ximas 2 horas

---

**ResponsÃ¡vel pela Auditoria:** GitHub Copilot  
**Data/Hora:** 2025-11-06 16:30:00 BRT
