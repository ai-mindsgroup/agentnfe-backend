#!/usr/bin/env python3
"""
Teste da Camada de Abstra√ß√£o LLM Manager
=======================================

Este script testa se a camada de abstra√ß√£o LLM Manager funciona corretamente:
- Detec√ß√£o autom√°tica de provedores dispon√≠veis
- Fallback autom√°tico entre provedores
- Integra√ß√£o com o orquestrador

Uso:
    python test_llm_abstraction.py
"""

from __future__ import annotations
import sys
from pathlib import Path

# Adiciona o diret√≥rio raiz do projeto ao PYTHONPATH
root_dir = Path(__file__).parent.parent
sys.path.insert(0, str(root_dir))

from src.llm.manager import get_llm_manager, LLMConfig, LLMProvider
from src.agent.orchestrator_agent import OrchestratorAgent
from src.utils.logging_config import get_logger

logger = get_logger(__name__)

def test_llm_manager_basic():
    """Testa funcionalidades b√°sicas do LLM Manager."""
    print("\n" + "="*60)
    print("üß™ TESTE 1: LLM Manager - Funcionalidades B√°sicas")
    print("="*60)
    
    try:
        # Inicializar manager
        manager = get_llm_manager()
        print(f"‚úÖ LLM Manager inicializado")
        
        # Verificar status
        status = manager.get_status()
        print(f"ü§ñ Provedor ativo: {status['active_provider']}")
        print(f"üìã Ordem de prefer√™ncia: {', '.join(status['preferred_order'])}")
        
        # Listar provedores dispon√≠veis
        print("\nüìä Status dos Provedores:")
        for provider, info in status['provider_status'].items():
            status_icon = "‚úÖ" if info['available'] else "‚ùå"
            print(f"   {status_icon} {provider.upper()}: {info['message']}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erro no teste do LLM Manager: {e}")
        return False

def test_llm_manager_chat():
    """Testa chamada de chat do LLM Manager."""
    print("\n" + "="*60)
    print("üß™ TESTE 2: LLM Manager - Chat")
    print("="*60)
    
    try:
        manager = get_llm_manager()
        
        # Configura√ß√£o de teste
        config = LLMConfig(temperature=0.1, max_tokens=100)
        
        # Prompt de teste
        prompt = "Responda em uma frase: Qual √© a capital do Brasil?"
        
        print(f"üìù Prompt: {prompt}")
        print("üîÑ Enviando para LLM...")
        
        # Fazer chamada
        response = manager.chat(prompt, config)
        
        if response.success:
            print(f"‚úÖ Resposta recebida via {response.provider.value}")
            print(f"üìÑ Conte√∫do: {response.content}")
            print(f"‚è±Ô∏è Tempo: {response.processing_time:.2f}s")
            print(f"üî¢ Tokens: {response.tokens_used}")
            return True
        else:
            print(f"‚ùå Falha na chamada: {response.error}")
            return False
            
    except Exception as e:
        print(f"‚ùå Erro no teste de chat: {e}")
        return False

def test_orchestrator_integration():
    """Testa integra√ß√£o do LLM Manager com o orquestrador."""
    print("\n" + "="*60)
    print("üß™ TESTE 3: Integra√ß√£o com Orquestrador")
    print("="*60)
    
    try:
        # Inicializar orquestrador
        print("üîß Inicializando orquestrador...")
        orchestrator = OrchestratorAgent()
        print("‚úÖ Orquestrador inicializado")
        
        # Verificar se LLM Manager est√° dispon√≠vel
        if orchestrator.llm_manager:
            print("‚úÖ LLM Manager integrado ao orquestrador")
            
            # Testar consulta
            query = "Quais s√£o os tipos de dados (num√©ricos, categ√≥ricos)?"
            print(f"üìù Consulta de teste: {query}")
            print("üîÑ Processando...")
            
            result = orchestrator.process(query)
            
            if result.get("metadata", {}).get("error", False):
                print(f"‚ùå Erro na consulta: {result.get('content')}")
                return False
            else:
                print("‚úÖ Consulta processada com sucesso")
                print(f"üìÑ Resposta: {result.get('content', '')[:200]}...")
                agents_used = result.get("metadata", {}).get("agents_used", [])
                print(f"ü§ñ Agentes usados: {', '.join(agents_used)}")
                return True
        else:
            print("‚ùå LLM Manager n√£o est√° integrado ao orquestrador")
            return False
            
    except Exception as e:
        print(f"‚ùå Erro no teste de integra√ß√£o: {e}")
        return False

def test_fallback_mechanism():
    """Testa mecanismo de fallback entre provedores."""
    print("\n" + "="*60)
    print("üß™ TESTE 4: Mecanismo de Fallback")
    print("="*60)
    
    try:
        manager = get_llm_manager()
        
        # Verificar quantos provedores est√£o dispon√≠veis
        status = manager.get_status()
        available_providers = [
            p for p, info in status['provider_status'].items() 
            if info['available']
        ]
        
        print(f"üìä Provedores dispon√≠veis: {len(available_providers)}")
        
        if len(available_providers) > 1:
            print("‚úÖ M√∫ltiplos provedores dispon√≠veis - fallback pode ser testado")
            
            # Testar com provedor espec√≠fico
            for provider_name in available_providers:
                try:
                    provider = LLMProvider(provider_name)
                    config = LLMConfig(temperature=0.1, max_tokens=50)
                    response = manager.chat("Diga ol√°", config, force_provider=provider)
                    
                    if response.success:
                        print(f"‚úÖ {provider.value}: {response.content[:50]}...")
                    else:
                        print(f"‚ùå {provider.value}: {response.error}")
                        
                except Exception as e:
                    print(f"‚ùå {provider_name}: Erro - {e}")
            
            return True
            
        elif len(available_providers) == 1:
            print(f"‚ö†Ô∏è Apenas um provedor dispon√≠vel ({available_providers[0]}) - fallback n√£o pode ser testado")
            return True
        else:
            print("‚ùå Nenhum provedor dispon√≠vel")
            return False
            
    except Exception as e:
        print(f"‚ùå Erro no teste de fallback: {e}")
        return False

def main():
    """Executa todos os testes."""
    print("\n" + "="*80)
    print("üöÄ TESTE DA CAMADA DE ABSTRA√á√ÉO LLM MANAGER".center(80))
    print("="*80)
    
    tests = [
        ("LLM Manager B√°sico", test_llm_manager_basic),
        ("Chat LLM Manager", test_llm_manager_chat),
        ("Integra√ß√£o Orquestrador", test_orchestrator_integration),
        ("Mecanismo Fallback", test_fallback_mechanism)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            success = test_func()
            results.append((test_name, success))
        except Exception as e:
            print(f"‚ùå Erro cr√≠tico no teste {test_name}: {e}")
            results.append((test_name, False))
    
    # Resumo dos resultados
    print("\n" + "="*60)
    print("üìä RESUMO DOS TESTES")
    print("="*60)
    
    passed = 0
    for test_name, success in results:
        status = "‚úÖ PASSOU" if success else "‚ùå FALHOU"
        print(f"{status} - {test_name}")
        if success:
            passed += 1
    
    print(f"\nüéØ Resultado Final: {passed}/{len(results)} testes passaram")
    
    if passed == len(results):
        print("üéâ Todos os testes passaram! A camada de abstra√ß√£o est√° funcionando corretamente.")
        return True
    else:
        print("‚ö†Ô∏è Alguns testes falharam. Verifique as configura√ß√µes dos provedores LLM.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)