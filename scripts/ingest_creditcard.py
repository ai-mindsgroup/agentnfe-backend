"""Ferramenta utilit√°ria para ingest√£o do dataset de fraude em cart√£o de cr√©dito.

Executa o pipeline RAG completo (chunking CSV, gera√ß√£o de embeddings e
armazenamento no vector store) utilizando os par√¢metros recomendados para o projeto.

Uso b√°sico:
    python scripts/ingest_creditcard.py

Par√¢metros opcionais permitem alterar o caminho do CSV, fonte, chunking e
provedor de embeddings.
"""
from __future__ import annotations

import argparse
import sys
from pathlib import Path
from typing import Optional

# Garantir que o diret√≥rio raiz do projeto esteja no PYTHONPATH quando o script
# for executado diretamente (python scripts/ingest_creditcard.py)
PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from src.agent.rag_agent import RAGAgent
from src.embeddings.generator import EmbeddingProvider

DEFAULT_CSV_PATH = Path("data/creditcard.csv")
DEFAULT_SOURCE_ID = "creditcard_full"


def _parse_args(argv: Optional[list[str]] = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Ingesta o dataset de fraude em cart√£o de cr√©dito para o vector store",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        "--csv-path",
        type=Path,
        default=DEFAULT_CSV_PATH,
        help="Caminho para o arquivo CSV a ser ingerido.",
    )
    parser.add_argument(
        "--source-id",
        type=str,
        default=DEFAULT_SOURCE_ID,
        help="Identificador da fonte a ser armazenado no vector store.",
    )
    parser.add_argument(
        "--chunk-size-rows",
        type=int,
        default=20,
        help="Quantidade de linhas por chunk CSV (antes do overlap).",
    )
    parser.add_argument(
        "--overlap-rows",
        type=int,
        default=4,
        help="Quantidade de linhas de overlap entre chunks CSV consecutivos.",
    )
    parser.add_argument(
        "--chunk-size-chars",
        type=int,
        default=512,
        help="Tamanho do chunk textual em caracteres (para fontes n√£o-CSV).",
    )
    parser.add_argument(
        "--chunk-overlap-chars",
        type=int,
        default=50,
        help="Overlap em caracteres entre chunks textuais (para fontes n√£o-CSV).",
    )
    parser.add_argument(
        "--provider",
        choices=[provider.value for provider in EmbeddingProvider],
        default=EmbeddingProvider.SENTENCE_TRANSFORMER.value,
        help="Provedor de embeddings a ser utilizado.",
    )
    parser.add_argument(
        "--encoding",
        type=str,
        default="utf-8",
        help="Codifica√ß√£o usada para leitura do CSV.",
    )
    parser.add_argument(
        "--errors",
        type=str,
        default="ignore",
        help="Pol√≠tica de tratamento de erros de decodifica√ß√£o ao ler o CSV.",
    )
    return parser.parse_args(argv)


def _resolve_provider(value: str) -> EmbeddingProvider:
    for provider in EmbeddingProvider:
        if value == provider.value or value.lower() == provider.name.lower():
            return provider
    raise ValueError(f"Provedor de embeddings n√£o suportado: {value}")


def main(argv: Optional[list[str]] = None) -> int:
    args = _parse_args(argv)

    csv_path = args.csv_path.resolve()
    if not csv_path.exists():
        print(f"‚ùå Arquivo CSV n√£o encontrado: {csv_path}", file=sys.stderr)
        return 1

    if args.chunk_size_rows <= 0:
        print("‚ùå chunk_size_rows deve ser maior que zero.", file=sys.stderr)
        return 1

    provider = _resolve_provider(args.provider)

    print("üöÄ Iniciando ingest√£o do CSV...", flush=True)
    print(f"   ‚Ä¢ Arquivo: {csv_path}")
    print(f"   ‚Ä¢ Fonte (source_id): {args.source_id}")
    print(f"   ‚Ä¢ Chunk CSV: {args.chunk_size_rows} linhas (+{args.overlap_rows} overlap)")
    print(f"   ‚Ä¢ Provedor de embeddings: {provider.value}")

    agent = RAGAgent(
        embedding_provider=provider,
        chunk_size=args.chunk_size_chars,
        chunk_overlap=args.chunk_overlap_chars,
        csv_chunk_size_rows=args.chunk_size_rows,
        csv_overlap_rows=args.overlap_rows,
    )

    result = agent.ingest_csv_file(
        file_path=str(csv_path),
        source_id=args.source_id,
        encoding=args.encoding,
        errors=args.errors,
    )

    content = result.get("content", "")
    metadata = result.get("metadata", {}) or {}

    if metadata.get("error"):
        print("‚ùå Falha na ingest√£o:")
        print(f"   ‚Ä¢ Mensagem: {content}")
        if metadata:
            print(f"   ‚Ä¢ Detalhes: {metadata}")
        return 2

    print("‚úÖ Ingest√£o conclu√≠da com sucesso!")
    if content:
        print("---")
        print(content)
        print("---")

    if metadata:
        print("üìä Estat√≠sticas do processamento:")
        stats_lines = [
            f"   ‚Ä¢ Fonte: {metadata.get('source_id')}",
            f"   ‚Ä¢ Tipo da fonte: {metadata.get('source_type')}",
            f"   ‚Ä¢ Chunks gerados: {metadata.get('chunks_created')}",
            f"   ‚Ä¢ Embeddings gerados: {metadata.get('embeddings_generated')}",
            f"   ‚Ä¢ Embeddings armazenados: {metadata.get('embeddings_stored')}",
            f"   ‚Ä¢ Estrat√©gia de chunking: {metadata.get('chunk_strategy')}",
            f"   ‚Ä¢ Tempo de processamento (s): {metadata.get('processing_time'):.2f}" if metadata.get('processing_time') is not None else None,
        ]
        for line in stats_lines:
            if line is not None:
                print(line)

        chunk_stats = metadata.get("chunk_stats") or {}
        if chunk_stats:
            print("   ‚Ä¢ CSV total de linhas processadas:", chunk_stats.get("total_csv_rows"))
            print("   ‚Ä¢ M√©dia de linhas por chunk:", chunk_stats.get("avg_csv_rows"))
            print("   ‚Ä¢ Overlap total (linhas):", chunk_stats.get("total_csv_overlap_rows"))

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
